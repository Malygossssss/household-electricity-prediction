实验一：LSTM 模型（基础任务）

实验 1-1：输入90天，预测90天（默认基准）：

python train.py --train train.csv --test test.csv \
    --model lstm --input-days 90 --pred-days 90 \
    --batch-size 32 --epochs 30 --lr 1e-3

Epoch 1: loss=2561267.9225 mse=2340474.2500 mae=1432.5599
Epoch 2: loss=2557850.6585 mse=2335887.2500 mae=1431.0028
Epoch 3: loss=2552830.7817 mse=2331071.0000 mae=1429.3661
Epoch 4: loss=2547948.3063 mse=2326470.0000 mae=1427.8009
Epoch 5: loss=2543357.0176 mse=2322260.2500 mae=1426.3667
Epoch 6: loss=2539113.7289 mse=2318258.5000 mae=1425.0021
Epoch 7: loss=2535040.0423 mse=2314419.0000 mae=1423.6917
Epoch 8: loss=2531114.5070 mse=2310655.5000 mae=1422.4060
Epoch 9: loss=2527235.6127 mse=2306999.7500 mae=1421.1561
Epoch 10: loss=2523453.3275 mse=2303373.7500 mae=1419.9152
Epoch 11: loss=2519717.9366 mse=2299782.2500 mae=1418.6869
Epoch 12: loss=2516017.9437 mse=2296229.0000 mae=1417.4728
Epoch 13: loss=2512345.4120 mse=2292714.0000 mae=1416.2705
Epoch 14: loss=2508714.2641 mse=2289218.5000 mae=1415.0737
Epoch 15: loss=2505091.5986 mse=2285761.5000 mae=1413.8895
Epoch 16: loss=2501500.9859 mse=2282314.2500 mae=1412.7073
Epoch 17: loss=2497927.7183 mse=2278880.0000 mae=1411.5284
Epoch 18: loss=2494368.3944 mse=2275460.2500 mae=1410.3536
Epoch 19: loss=2490823.0282 mse=2272057.5000 mae=1409.1838
Epoch 20: loss=2487308.4261 mse=2268648.7500 mae=1408.0109
Epoch 21: loss=2483772.5176 mse=2265284.5000 mae=1406.8521
Epoch 22: loss=2480287.8204 mse=2261900.0000 mae=1405.6855
Epoch 23: loss=2476785.4225 mse=2258547.5000 mae=1404.5289
Epoch 24: loss=2473311.5387 mse=2255191.7500 mae=1403.3704
Epoch 25: loss=2469839.3996 mse=2251847.2500 mae=1402.2147
Epoch 26: loss=2466375.6866 mse=2248521.0000 mae=1401.0641
Epoch 27: loss=2462910.1972 mse=2245224.2500 mae=1399.9230
Epoch 28: loss=2459475.6338 mse=2241914.2500 mae=1398.7759
Epoch 29: loss=2456046.6514 mse=2238597.0000 mae=1397.6257
Epoch 30: loss=2452616.3697 mse=2235289.5000 mae=1396.4778

实验 1-2：输入30天，预测90天（窗口缩小）：

python train.py --train train.csv --test test.csv \
    --model lstm --input-days 30 --pred-days 90 \
    --batch-size 32 --epochs 30 --lr 1e-3

Epoch 1: loss=2626167.4602 mse=2376630.5000 mae=1449.4452
Epoch 2: loss=2621891.5430 mse=2370950.7500 mae=1447.5350
Epoch 3: loss=2616027.5653 mse=2365596.5000 mae=1445.7317
Epoch 4: loss=2610831.1656 mse=2360846.0000 mae=1444.1298
Epoch 5: loss=2606075.8885 mse=2356381.2500 mae=1442.6224
Epoch 6: loss=2601554.6704 mse=2352086.2500 mae=1441.1708
Epoch 7: loss=2597175.0828 mse=2347921.5000 mae=1439.7621
Epoch 8: loss=2592912.5860 mse=2343818.0000 mae=1438.3727
Epoch 9: loss=2588699.7325 mse=2339798.5000 mae=1437.0103
Epoch 10: loss=2584547.9299 mse=2335825.0000 mae=1435.6641
Epoch 11: loss=2580464.3081 mse=2331848.7500 mae=1434.3186
Epoch 12: loss=2576381.9045 mse=2327941.0000 mae=1432.9949
Epoch 13: loss=2572338.8997 mse=2324071.7500 mae=1431.6831
Epoch 14: loss=2568329.1417 mse=2320199.7500 mae=1430.3689
Epoch 15: loss=2564341.1354 mse=2316334.5000 mae=1429.0560
Epoch 16: loss=2560366.8694 mse=2312489.5000 mae=1427.7488
Epoch 17: loss=2556404.3169 mse=2308680.5000 mae=1426.4523
Epoch 18: loss=2552472.5350 mse=2304872.5000 mae=1425.1550
Epoch 19: loss=2548530.7643 mse=2301104.7500 mae=1423.8704
Epoch 20: loss=2544626.4857 mse=2297326.5000 mae=1422.5809
Epoch 21: loss=2540729.1449 mse=2293554.7500 mae=1421.2924
Epoch 22: loss=2536836.3615 mse=2289799.0000 mae=1420.0083
Epoch 23: loss=2532956.5175 mse=2286065.0000 mae=1418.7303
Epoch 24: loss=2529097.2070 mse=2282324.2500 mae=1417.4487
Epoch 25: loss=2525239.5080 mse=2278594.2500 mae=1416.1699
Epoch 26: loss=2521381.1242 mse=2274895.2500 mae=1414.9005
Epoch 27: loss=2517555.3758 mse=2271181.2500 mae=1413.6245
Epoch 28: loss=2513724.1242 mse=2267488.2500 mae=1412.3547
Epoch 29: loss=2509897.2277 mse=2263812.2500 mae=1411.0896
Epoch 30: loss=2506087.9268 mse=2260126.5000 mae=1409.8199

实验 1-3：输入90天，预测365天（长期趋势）：

python train.py --train train.csv --test test.csv \
    --model lstm --input-days 90 --pred-days 365 \
    --batch-size 32 --epochs 30 --lr 1e-3

Epoch 1: loss=2865628.9360 mse=2633588.2500 mae=1533.5387
Epoch 2: loss=2864350.0913 mse=2631319.0000 mae=1532.8109
Epoch 3: loss=2861641.9735 mse=2628431.0000 mae=1531.8856
Epoch 4: loss=2858573.4147 mse=2625455.2500 mae=1530.9319
Epoch 5: loss=2855591.7637 mse=2622696.5000 mae=1530.0476
Epoch 6: loss=2852817.3490 mse=2620103.5000 mae=1529.2161
Epoch 7: loss=2850193.0725 mse=2617627.0000 mae=1528.4214
Epoch 8: loss=2847667.1433 mse=2615232.2500 mae=1527.6526
Epoch 9: loss=2845215.8387 mse=2612897.7500 mae=1526.9027
Epoch 10: loss=2842826.9974 mse=2610611.2500 mae=1526.1681
Epoch 11: loss=2840481.9881 mse=2608363.2500 mae=1525.4456
Epoch 12: loss=2838174.3336 mse=2606159.5000 mae=1524.7368
Epoch 13: loss=2835893.3311 mse=2603956.0000 mae=1524.0277
Epoch 14: loss=2833637.7406 mse=2601785.2500 mae=1523.3291
Epoch 15: loss=2831403.1732 mse=2599632.7500 mae=1522.6356
Epoch 16: loss=2829186.2799 mse=2597496.5000 mae=1521.9474
Epoch 17: loss=2826983.0119 mse=2595373.5000 mae=1521.2631
Epoch 18: loss=2824792.8541 mse=2593262.5000 mae=1520.5824
Epoch 19: loss=2822616.7935 mse=2591162.5000 mae=1519.9053
Epoch 20: loss=2820450.1578 mse=2589072.5000 mae=1519.2313
Epoch 21: loss=2818292.9215 mse=2586991.2500 mae=1518.5603
Epoch 22: loss=2816146.1638 mse=2584916.2500 mae=1517.8909
Epoch 23: loss=2814003.9411 mse=2582851.0000 mae=1517.2245
Epoch 24: loss=2811872.5785 mse=2580793.5000 mae=1516.5601
Epoch 25: loss=2809749.4138 mse=2578743.0000 mae=1515.8978
Epoch 26: loss=2807630.9735 mse=2576696.2500 mae=1515.2363
Epoch 27: loss=2805517.8097 mse=2574658.0000 mae=1514.5769
Epoch 28: loss=2803411.0614 mse=2572622.5000 mae=1513.9188
Epoch 29: loss=2801309.7850 mse=2570593.5000 mae=1513.2620
Epoch 30: loss=2799213.0631 mse=2568568.7500 mae=1512.6066

实验二：Transformer 模型（基础任务）

实验 2-1：输入90天，预测90天（直接对比 LSTM）：

python train.py --train train.csv --test test.csv \
    --model transformer --input-days 90 --pred-days 90 \
    --batch-size 32 --epochs 30 --lr 1e-3

Epoch 1: loss=2559841.0141 mse=2338553.2500 mae=1431.9091
Epoch 2: loss=2556336.3099 mse=2334894.7500 mae=1430.6663
Epoch 3: loss=2552319.9331 mse=2330668.5000 mae=1429.2299
Epoch 4: loss=2547718.2007 mse=2325922.5000 mae=1427.6147
Epoch 5: loss=2542597.7254 mse=2320655.7500 mae=1425.8202
Epoch 6: loss=2536912.5599 mse=2314870.5000 mae=1423.8463
Epoch 7: loss=2530681.7430 mse=2308567.0000 mae=1421.6925
Epoch 8: loss=2523920.2817 mse=2301766.7500 mae=1419.3661
Epoch 9: loss=2516634.5563 mse=2294425.7500 mae=1416.8566
Epoch 10: loss=2508773.3028 mse=2286637.2500 mae=1414.1898
Epoch 11: loss=2500459.4542 mse=2278271.0000 mae=1411.3198
Epoch 12: loss=2491574.2711 mse=2269422.7500 mae=1408.2777
Epoch 13: loss=2482159.3275 mse=2260099.5000 mae=1405.0649
Epoch 14: loss=2472231.0211 mse=2250268.0000 mae=1401.6691
Epoch 15: loss=2461806.8627 mse=2239898.7500 mae=1398.0779
Epoch 16: loss=2450815.8239 mse=2229108.0000 mae=1394.3309
Epoch 17: loss=2439357.9683 mse=2217784.7500 mae=1390.3875
Epoch 18: loss=2427354.3134 mse=2206002.2500 mae=1386.2719
Epoch 19: loss=2414897.5599 mse=2193702.5000 mae=1381.9620
Epoch 20: loss=2401894.9754 mse=2180957.7500 mae=1377.4816
Epoch 21: loss=2388409.6585 mse=2167792.7500 mae=1372.8376
Epoch 22: loss=2374456.0176 mse=2154140.0000 mae=1368.0043
Epoch 23: loss=2360104.6831 mse=2139936.0000 mae=1362.9574
Epoch 24: loss=2345130.5176 mse=2125451.7500 mae=1357.7904
Epoch 25: loss=2329823.3310 mse=2110475.5000 mae=1352.4265
Epoch 26: loss=2314027.3486 mse=2095090.5000 mae=1346.8936
Epoch 27: loss=2297819.0000 mse=2079283.8750 mae=1341.1908
Epoch 28: loss=2281218.6585 mse=2063030.2500 mae=1335.3167
Epoch 29: loss=2264136.4683 mse=2046481.2500 mae=1329.3123
Epoch 30: loss=2246686.5317 mse=2029539.3750 mae=1323.1487

实验 2-2：输入90天，预测365天（长期趋势）：

python train.py --train train.csv --test test.csv \
    --model transformer --input-days 90 --pred-days 365 \
    --batch-size 32 --epochs 30 --lr 1e-3

Epoch 1: loss=2864947.4872 mse=2632223.2500 mae=1533.1075
Epoch 2: loss=2863090.1391 mse=2630325.0000 mae=1532.4996
Epoch 3: loss=2861054.5333 mse=2628210.2500 mae=1531.8228
Epoch 4: loss=2858801.7082 mse=2625871.5000 mae=1531.0743
Epoch 5: loss=2856325.6186 mse=2623334.5000 mae=1530.2616
Epoch 6: loss=2853650.4002 mse=2620618.0000 mae=1529.3911
Epoch 7: loss=2850803.6220 mse=2617739.2500 mae=1528.4674
Epoch 8: loss=2847772.2491 mse=2614690.7500 mae=1527.4886
Epoch 9: loss=2844578.6997 mse=2611471.5000 mae=1526.4545
Epoch 10: loss=2841208.0691 mse=2608099.2500 mae=1525.3702
Epoch 11: loss=2837660.5094 mse=2604553.5000 mae=1524.2297
Epoch 12: loss=2833948.3191 mse=2600856.2500 mae=1523.0397
Epoch 13: loss=2830070.7619 mse=2596990.5000 mae=1521.7943
Epoch 14: loss=2826021.6297 mse=2592946.7500 mae=1520.4907
Epoch 15: loss=2821792.9693 mse=2588750.2500 mae=1519.1370
Epoch 16: loss=2817396.9582 mse=2584391.2500 mae=1517.7308
Epoch 17: loss=2812832.6041 mse=2579861.0000 mae=1516.2687
Epoch 18: loss=2808079.1314 mse=2575163.5000 mae=1514.7504
Epoch 19: loss=2803182.7338 mse=2570296.0000 mae=1513.1760
Epoch 20: loss=2798091.1570 mse=2565265.5000 mae=1511.5469
Epoch 21: loss=2792827.6945 mse=2560062.0000 mae=1509.8606
Epoch 22: loss=2787367.9121 mse=2554693.0000 mae=1508.1182
Epoch 23: loss=2781765.2389 mse=2549156.0000 mae=1506.3186
Epoch 24: loss=2775984.4036 mse=2543452.5000 mae=1504.4626
Epoch 25: loss=2770027.6945 mse=2537576.5000 mae=1502.5483
Epoch 26: loss=2763882.2585 mse=2531553.2500 mae=1500.5829
Epoch 27: loss=2757566.0964 mse=2525360.5000 mae=1498.5592
Epoch 28: loss=2751084.8848 mse=2518978.0000 mae=1496.4712
Epoch 29: loss=2744455.8046 mse=2512442.5000 mae=1494.3301
Epoch 30: loss=2737611.5026 mse=2505760.5000 mae=1492.1387

创新模型（自由结构，保留格式）

LSTM + Attention：

python train.py --train train.csv --test test.csv \
    --model lstm_attn --input-days 90 --pred-days 90 \
    --batch-size 32 --epochs 30 --lr 1e-3

Epoch 1: loss=2560809.0739 mse=2337512.5000 mae=1431.5555
Epoch 2: loss=2538889.0423 mse=2284418.5000 mae=1413.4253
Epoch 3: loss=2424360.9894 mse=2086351.2500 mae=1343.7043
Epoch 4: loss=2105277.0739 mse=1639783.8750 mae=1172.3190
Epoch 5: loss=1513311.4789 mse=968985.9375 mae=857.0731
Epoch 6: loss=805958.6166 mse=405436.5000 mae=511.9489
Epoch 7: loss=404501.9388 mse=295704.4688 mae=423.7008
Epoch 8: loss=358592.9705 mse=299783.4375 mae=426.5635
Epoch 9: loss=354636.6857 mse=291878.3438 mae=420.4814
Epoch 10: loss=353135.3099 mse=290189.9375 mae=419.3064
Epoch 11: loss=351681.2513 mse=291315.3125 mae=420.0557
Epoch 12: loss=354498.3706 mse=291865.7500 mae=420.4372
Epoch 13: loss=352059.8715 mse=290286.5000 mae=419.3683
Epoch 14: loss=354353.1083 mse=290932.8750 mae=419.8209
Epoch 15: loss=351599.4124 mse=292655.1875 mae=421.0359
Epoch 16: loss=353299.0511 mse=290576.6562 mae=419.5544
Epoch 17: loss=352135.8420 mse=291293.6562 mae=420.0553
Epoch 18: loss=352179.6206 mse=290783.7812 mae=419.7066
Epoch 19: loss=353161.7777 mse=292307.7812 mae=420.7655
Epoch 20: loss=352602.5150 mse=291177.6562 mae=419.9971
Epoch 21: loss=351452.4547 mse=292387.7188 mae=420.8224
Epoch 22: loss=355334.5810 mse=291023.3125 mae=419.8518
Epoch 23: loss=351765.8926 mse=290822.8750 mae=419.7271
Epoch 24: loss=350637.5577 mse=292167.2812 mae=420.6516
Epoch 25: loss=351305.4340 mse=292193.3125 mae=420.6976
Epoch 26: loss=350225.3420 mse=290718.5000 mae=419.6660
Epoch 27: loss=352409.4736 mse=290685.6875 mae=419.6340
Epoch 28: loss=351778.9111 mse=292287.6562 mae=420.7651
Epoch 29: loss=350476.6629 mse=290317.1562 mae=419.4224
Epoch 30: loss=352929.1479 mse=293234.6875 mae=421.4470







